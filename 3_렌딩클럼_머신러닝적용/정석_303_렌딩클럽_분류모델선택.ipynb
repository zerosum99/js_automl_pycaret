{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d44cbc-d1f1-480b-a8d5-8066e4b997d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f2a75a-da8e-4f13-985a-f2f884ed78dd",
   "metadata": {},
   "source": [
    "# 1. 모델 선정\n",
    "pycaret 패키지 내 AutoML을 적용해 데이터셋에 가장 적합한 모델을 선정한다.\n",
    "\n",
    "데이터 불러오기\n",
    "전처리와 변수 선정이 완료된 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52cb9b-2585-4659-a275-de78c335ab1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1964a5a-3282-4738-8e03-15b678298c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycaret    \n",
    "\n",
    "import sys, gc, warnings, datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c552e1-f626-47c9-9ca5-a260021c4f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01982507-2d28-4912-a86e-419d89d4cc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/a06411/Documents/GitHub/js_automl_pycaret/lending_club_da/Modeling'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b370d53e-2c7e-49df-bc69-06a272a68804",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_read = '/Users/a06411/Documents/data_hub/lending_club/lgb_selected.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359b3326-1282-4885-8003-7b10db20c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path_read )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be2ddd2-1acb-464b-a6b7-7ecd8a26a90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382351, 63)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce74657c-beee-4144-bd2b-ec5dd3bb0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52037c-a98e-4fdb-8843-5f8c2ab27c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4173bda-c548-482e-8929-0b223b1d9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.sample(frac=0.01, replace=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a023c0c5-68ee-4e5a-9653-87f72774a37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13824, 63)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6795f-2951-4f4e-9d3b-9ea7ece364df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c12441-ea37-498f-b80e-f07a4d78ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['int_rate', 'dti', 'annual_inc', 'mo_sin_old_rev_tl_op',\n",
       "       'acc_open_past_24mths', 'loan_amnt', 'emp_length', 'addr_state',\n",
       "       'revol_bal', 'term', 'sub_grade', 'funded_amnt_inv', 'installment',\n",
       "       'purpose', 'total_rev_hi_lim', 'fico_range_low', 'debt_settlement_flag',\n",
       "       'mort_acc', 'total_bc_limit', 'home_ownership', 'avg_cur_bal',\n",
       "       'all_util', 'mths_since_recent_bc', 'total_acc', 'open_acc_6m',\n",
       "       'bc_util', 'num_actv_rev_tl', 'funded_amnt', 'hardship_flag',\n",
       "       'num_rev_tl_bal_gt_0', 'mths_since_recent_inq', 'inq_last_6mths',\n",
       "       'num_il_tl', 'mo_sin_old_il_acct', 'num_rev_accts', 'num_tl_120dpd_2m',\n",
       "       'total_il_high_credit_limit', 'application_type', 'revol_util',\n",
       "       'tot_hi_cred_lim', 'delinq_2yrs', 'mo_sin_rcnt_tl', 'num_actv_bc_tl',\n",
       "       'mths_since_last_record', 'percent_bc_gt_75', 'bc_open_to_buy',\n",
       "       'max_bal_bc', 'grade', 'open_rv_24m', 'mo_sin_rcnt_rev_tl_op',\n",
       "       'pct_tl_nvr_dlq', 'verification_status', 'tot_cur_bal',\n",
       "       'total_bal_ex_mort', 'mths_since_last_major_derog', 'inq_fi',\n",
       "       'mths_since_rcnt_il', 'inq_last_12m', 'mths_since_last_delinq',\n",
       "       'num_bc_tl', 'loan_status', 'issue_d', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862ce18-4d3c-429a-b24c-7fa9fcded026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99921b26-ecab-489f-ba15-3c7b74a8063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3069775-876f-49f4-a9e7-1a80cb272f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [*df_sample.columns[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0415c37-97c5-4d15-9896-a56383470435",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_sample[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af543045-a270-4998-9962-be00fccb5d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eafa0_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eafa0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eafa0_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_eafa0_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_eafa0_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_eafa0_row0_col1\" class=\"data row0 col1\" >664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_eafa0_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_eafa0_row1_col1\" class=\"data row1 col1\" >loan_status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_eafa0_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_eafa0_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_eafa0_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_eafa0_row3_col1\" class=\"data row3 col1\" >(13980, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_eafa0_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_eafa0_row4_col1\" class=\"data row4 col1\" >(14916, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_eafa0_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_eafa0_row5_col1\" class=\"data row5 col1\" >(10467, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_eafa0_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_eafa0_row6_col1\" class=\"data row6 col1\" >(4449, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_eafa0_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_eafa0_row7_col1\" class=\"data row7 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_eafa0_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_eafa0_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_eafa0_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_eafa0_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_eafa0_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_eafa0_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_eafa0_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_eafa0_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_eafa0_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_eafa0_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_eafa0_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_eafa0_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_eafa0_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_eafa0_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_eafa0_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_eafa0_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_eafa0_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_eafa0_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_eafa0_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_eafa0_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eafa0_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_eafa0_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_eafa0_row18_col1\" class=\"data row18 col1\" >61a1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bd61e670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = setup(data = data, target = 'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb01bc0-c94f-4b11-9b57-cdffc739a249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f619eff-703f-4fc6-b950-001c46e44ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5e285 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5e285_row0_col0, #T_5e285_row0_col1, #T_5e285_row0_col3, #T_5e285_row0_col4, #T_5e285_row0_col5, #T_5e285_row0_col6, #T_5e285_row0_col7, #T_5e285_row1_col0, #T_5e285_row1_col1, #T_5e285_row1_col2, #T_5e285_row1_col3, #T_5e285_row1_col4, #T_5e285_row1_col5, #T_5e285_row1_col6, #T_5e285_row1_col7, #T_5e285_row2_col0, #T_5e285_row2_col2, #T_5e285_row2_col3, #T_5e285_row2_col4, #T_5e285_row2_col5, #T_5e285_row2_col6, #T_5e285_row3_col0, #T_5e285_row3_col1, #T_5e285_row3_col2, #T_5e285_row3_col3, #T_5e285_row3_col4, #T_5e285_row3_col5, #T_5e285_row3_col6, #T_5e285_row3_col7, #T_5e285_row4_col0, #T_5e285_row4_col1, #T_5e285_row4_col2, #T_5e285_row4_col3, #T_5e285_row4_col4, #T_5e285_row4_col5, #T_5e285_row4_col6, #T_5e285_row4_col7, #T_5e285_row5_col0, #T_5e285_row5_col1, #T_5e285_row5_col2, #T_5e285_row5_col3, #T_5e285_row5_col4, #T_5e285_row5_col5, #T_5e285_row5_col6, #T_5e285_row5_col7, #T_5e285_row6_col0, #T_5e285_row6_col1, #T_5e285_row6_col2, #T_5e285_row6_col3, #T_5e285_row6_col4, #T_5e285_row6_col5, #T_5e285_row6_col7, #T_5e285_row7_col0, #T_5e285_row7_col1, #T_5e285_row7_col2, #T_5e285_row7_col3, #T_5e285_row7_col4, #T_5e285_row7_col5, #T_5e285_row7_col6, #T_5e285_row7_col7, #T_5e285_row8_col0, #T_5e285_row8_col1, #T_5e285_row8_col2, #T_5e285_row8_col3, #T_5e285_row8_col5, #T_5e285_row8_col6, #T_5e285_row8_col7, #T_5e285_row9_col0, #T_5e285_row9_col1, #T_5e285_row9_col2, #T_5e285_row9_col4, #T_5e285_row9_col6, #T_5e285_row9_col7, #T_5e285_row10_col0, #T_5e285_row10_col1, #T_5e285_row10_col2, #T_5e285_row10_col3, #T_5e285_row10_col4, #T_5e285_row10_col5, #T_5e285_row10_col6, #T_5e285_row10_col7, #T_5e285_row11_col0, #T_5e285_row11_col1, #T_5e285_row11_col2, #T_5e285_row11_col3, #T_5e285_row11_col4, #T_5e285_row11_col5, #T_5e285_row11_col6, #T_5e285_row11_col7, #T_5e285_row12_col0, #T_5e285_row12_col1, #T_5e285_row12_col2, #T_5e285_row12_col3, #T_5e285_row12_col4, #T_5e285_row12_col5, #T_5e285_row12_col6, #T_5e285_row12_col7, #T_5e285_row13_col0, #T_5e285_row13_col1, #T_5e285_row13_col2, #T_5e285_row13_col3, #T_5e285_row13_col4, #T_5e285_row13_col5, #T_5e285_row13_col6, #T_5e285_row13_col7, #T_5e285_row14_col0, #T_5e285_row14_col1, #T_5e285_row14_col2, #T_5e285_row14_col3, #T_5e285_row14_col4, #T_5e285_row14_col5, #T_5e285_row14_col6, #T_5e285_row14_col7, #T_5e285_row15_col0, #T_5e285_row15_col1, #T_5e285_row15_col2, #T_5e285_row15_col3, #T_5e285_row15_col4, #T_5e285_row15_col5, #T_5e285_row15_col6, #T_5e285_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5e285_row0_col2, #T_5e285_row2_col1, #T_5e285_row2_col7, #T_5e285_row6_col6, #T_5e285_row8_col4, #T_5e285_row9_col3, #T_5e285_row9_col5 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_5e285_row0_col8, #T_5e285_row1_col8, #T_5e285_row2_col8, #T_5e285_row3_col8, #T_5e285_row4_col8, #T_5e285_row5_col8, #T_5e285_row6_col8, #T_5e285_row7_col8, #T_5e285_row9_col8, #T_5e285_row10_col8, #T_5e285_row11_col8, #T_5e285_row12_col8, #T_5e285_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_5e285_row8_col8, #T_5e285_row13_col8, #T_5e285_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5e285\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5e285_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_5e285_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_5e285_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_5e285_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_5e285_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_5e285_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_5e285_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_5e285_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_5e285_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_5e285_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_5e285_row0_col1\" class=\"data row0 col1\" >0.8282</td>\n",
       "      <td id=\"T_5e285_row0_col2\" class=\"data row0 col2\" >0.7742</td>\n",
       "      <td id=\"T_5e285_row0_col3\" class=\"data row0 col3\" >0.2156</td>\n",
       "      <td id=\"T_5e285_row0_col4\" class=\"data row0 col4\" >0.8610</td>\n",
       "      <td id=\"T_5e285_row0_col5\" class=\"data row0 col5\" >0.3446</td>\n",
       "      <td id=\"T_5e285_row0_col6\" class=\"data row0 col6\" >0.2846</td>\n",
       "      <td id=\"T_5e285_row0_col7\" class=\"data row0 col7\" >0.3764</td>\n",
       "      <td id=\"T_5e285_row0_col8\" class=\"data row0 col8\" >0.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row1\" class=\"row_heading level0 row1\" >catboost</th>\n",
       "      <td id=\"T_5e285_row1_col0\" class=\"data row1 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_5e285_row1_col1\" class=\"data row1 col1\" >0.8268</td>\n",
       "      <td id=\"T_5e285_row1_col2\" class=\"data row1 col2\" >0.7706</td>\n",
       "      <td id=\"T_5e285_row1_col3\" class=\"data row1 col3\" >0.2521</td>\n",
       "      <td id=\"T_5e285_row1_col4\" class=\"data row1 col4\" >0.7628</td>\n",
       "      <td id=\"T_5e285_row1_col5\" class=\"data row1 col5\" >0.3787</td>\n",
       "      <td id=\"T_5e285_row1_col6\" class=\"data row1 col6\" >0.3066</td>\n",
       "      <td id=\"T_5e285_row1_col7\" class=\"data row1 col7\" >0.3707</td>\n",
       "      <td id=\"T_5e285_row1_col8\" class=\"data row1 col8\" >1.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_5e285_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_5e285_row2_col1\" class=\"data row2 col1\" >0.8298</td>\n",
       "      <td id=\"T_5e285_row2_col2\" class=\"data row2 col2\" >0.7702</td>\n",
       "      <td id=\"T_5e285_row2_col3\" class=\"data row2 col3\" >0.2252</td>\n",
       "      <td id=\"T_5e285_row2_col4\" class=\"data row2 col4\" >0.8599</td>\n",
       "      <td id=\"T_5e285_row2_col5\" class=\"data row2 col5\" >0.3566</td>\n",
       "      <td id=\"T_5e285_row2_col6\" class=\"data row2 col6\" >0.2954</td>\n",
       "      <td id=\"T_5e285_row2_col7\" class=\"data row2 col7\" >0.3847</td>\n",
       "      <td id=\"T_5e285_row2_col8\" class=\"data row2 col8\" >0.4467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_5e285_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_5e285_row3_col1\" class=\"data row3 col1\" >0.8213</td>\n",
       "      <td id=\"T_5e285_row3_col2\" class=\"data row3 col2\" >0.7613</td>\n",
       "      <td id=\"T_5e285_row3_col3\" class=\"data row3 col3\" >0.2657</td>\n",
       "      <td id=\"T_5e285_row3_col4\" class=\"data row3 col4\" >0.6937</td>\n",
       "      <td id=\"T_5e285_row3_col5\" class=\"data row3 col5\" >0.3840</td>\n",
       "      <td id=\"T_5e285_row3_col6\" class=\"data row3 col6\" >0.3030</td>\n",
       "      <td id=\"T_5e285_row3_col7\" class=\"data row3 col7\" >0.3511</td>\n",
       "      <td id=\"T_5e285_row3_col8\" class=\"data row3 col8\" >0.7233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_5e285_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_5e285_row4_col1\" class=\"data row4 col1\" >0.8256</td>\n",
       "      <td id=\"T_5e285_row4_col2\" class=\"data row4 col2\" >0.7611</td>\n",
       "      <td id=\"T_5e285_row4_col3\" class=\"data row4 col3\" >0.2393</td>\n",
       "      <td id=\"T_5e285_row4_col4\" class=\"data row4 col4\" >0.7710</td>\n",
       "      <td id=\"T_5e285_row4_col5\" class=\"data row4 col5\" >0.3649</td>\n",
       "      <td id=\"T_5e285_row4_col6\" class=\"data row4 col6\" >0.2950</td>\n",
       "      <td id=\"T_5e285_row4_col7\" class=\"data row4 col7\" >0.3636</td>\n",
       "      <td id=\"T_5e285_row4_col8\" class=\"data row4 col8\" >1.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_5e285_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_5e285_row5_col1\" class=\"data row5 col1\" >0.8193</td>\n",
       "      <td id=\"T_5e285_row5_col2\" class=\"data row5 col2\" >0.7451</td>\n",
       "      <td id=\"T_5e285_row5_col3\" class=\"data row5 col3\" >0.2065</td>\n",
       "      <td id=\"T_5e285_row5_col4\" class=\"data row5 col4\" >0.7531</td>\n",
       "      <td id=\"T_5e285_row5_col5\" class=\"data row5 col5\" >0.3234</td>\n",
       "      <td id=\"T_5e285_row5_col6\" class=\"data row5 col6\" >0.2565</td>\n",
       "      <td id=\"T_5e285_row5_col7\" class=\"data row5 col7\" >0.3291</td>\n",
       "      <td id=\"T_5e285_row5_col8\" class=\"data row5 col8\" >0.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row6\" class=\"row_heading level0 row6\" >xgboost</th>\n",
       "      <td id=\"T_5e285_row6_col0\" class=\"data row6 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_5e285_row6_col1\" class=\"data row6 col1\" >0.8157</td>\n",
       "      <td id=\"T_5e285_row6_col2\" class=\"data row6 col2\" >0.7412</td>\n",
       "      <td id=\"T_5e285_row6_col3\" class=\"data row6 col3\" >0.2958</td>\n",
       "      <td id=\"T_5e285_row6_col4\" class=\"data row6 col4\" >0.6288</td>\n",
       "      <td id=\"T_5e285_row6_col5\" class=\"data row6 col5\" >0.4020</td>\n",
       "      <td id=\"T_5e285_row6_col6\" class=\"data row6 col6\" >0.3095</td>\n",
       "      <td id=\"T_5e285_row6_col7\" class=\"data row6 col7\" >0.3404</td>\n",
       "      <td id=\"T_5e285_row6_col8\" class=\"data row6 col8\" >0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row7\" class=\"row_heading level0 row7\" >ada</th>\n",
       "      <td id=\"T_5e285_row7_col0\" class=\"data row7 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_5e285_row7_col1\" class=\"data row7 col1\" >0.8184</td>\n",
       "      <td id=\"T_5e285_row7_col2\" class=\"data row7 col2\" >0.7377</td>\n",
       "      <td id=\"T_5e285_row7_col3\" class=\"data row7 col3\" >0.2357</td>\n",
       "      <td id=\"T_5e285_row7_col4\" class=\"data row7 col4\" >0.6984</td>\n",
       "      <td id=\"T_5e285_row7_col5\" class=\"data row7 col5\" >0.3520</td>\n",
       "      <td id=\"T_5e285_row7_col6\" class=\"data row7 col6\" >0.2755</td>\n",
       "      <td id=\"T_5e285_row7_col7\" class=\"data row7 col7\" >0.3310</td>\n",
       "      <td id=\"T_5e285_row7_col8\" class=\"data row7 col8\" >0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row8\" class=\"row_heading level0 row8\" >qda</th>\n",
       "      <td id=\"T_5e285_row8_col0\" class=\"data row8 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_5e285_row8_col1\" class=\"data row8 col1\" >0.8138</td>\n",
       "      <td id=\"T_5e285_row8_col2\" class=\"data row8 col2\" >0.7196</td>\n",
       "      <td id=\"T_5e285_row8_col3\" class=\"data row8 col3\" >0.1190</td>\n",
       "      <td id=\"T_5e285_row8_col4\" class=\"data row8 col4\" >0.9406</td>\n",
       "      <td id=\"T_5e285_row8_col5\" class=\"data row8 col5\" >0.2112</td>\n",
       "      <td id=\"T_5e285_row8_col6\" class=\"data row8 col6\" >0.1723</td>\n",
       "      <td id=\"T_5e285_row8_col7\" class=\"data row8 col7\" >0.2964</td>\n",
       "      <td id=\"T_5e285_row8_col8\" class=\"data row8 col8\" >0.2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_5e285_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_5e285_row9_col1\" class=\"data row9 col1\" >0.6002</td>\n",
       "      <td id=\"T_5e285_row9_col2\" class=\"data row9 col2\" >0.6683</td>\n",
       "      <td id=\"T_5e285_row9_col3\" class=\"data row9 col3\" >0.6732</td>\n",
       "      <td id=\"T_5e285_row9_col4\" class=\"data row9 col4\" >0.2988</td>\n",
       "      <td id=\"T_5e285_row9_col5\" class=\"data row9 col5\" >0.4138</td>\n",
       "      <td id=\"T_5e285_row9_col6\" class=\"data row9 col6\" >0.1740</td>\n",
       "      <td id=\"T_5e285_row9_col7\" class=\"data row9 col7\" >0.2072</td>\n",
       "      <td id=\"T_5e285_row9_col8\" class=\"data row9 col8\" >0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row10\" class=\"row_heading level0 row10\" >lr</th>\n",
       "      <td id=\"T_5e285_row10_col0\" class=\"data row10 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_5e285_row10_col1\" class=\"data row10 col1\" >0.7889</td>\n",
       "      <td id=\"T_5e285_row10_col2\" class=\"data row10 col2\" >0.6539</td>\n",
       "      <td id=\"T_5e285_row10_col3\" class=\"data row10 col3\" >0.0059</td>\n",
       "      <td id=\"T_5e285_row10_col4\" class=\"data row10 col4\" >0.4784</td>\n",
       "      <td id=\"T_5e285_row10_col5\" class=\"data row10 col5\" >0.0116</td>\n",
       "      <td id=\"T_5e285_row10_col6\" class=\"data row10 col6\" >0.0038</td>\n",
       "      <td id=\"T_5e285_row10_col7\" class=\"data row10 col7\" >0.0254</td>\n",
       "      <td id=\"T_5e285_row10_col8\" class=\"data row10 col8\" >1.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_5e285_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_5e285_row11_col1\" class=\"data row11 col1\" >0.7375</td>\n",
       "      <td id=\"T_5e285_row11_col2\" class=\"data row11 col2\" >0.6192</td>\n",
       "      <td id=\"T_5e285_row11_col3\" class=\"data row11 col3\" >0.4157</td>\n",
       "      <td id=\"T_5e285_row11_col4\" class=\"data row11 col4\" >0.3831</td>\n",
       "      <td id=\"T_5e285_row11_col5\" class=\"data row11 col5\" >0.3984</td>\n",
       "      <td id=\"T_5e285_row11_col6\" class=\"data row11 col6\" >0.2310</td>\n",
       "      <td id=\"T_5e285_row11_col7\" class=\"data row11 col7\" >0.2314</td>\n",
       "      <td id=\"T_5e285_row11_col8\" class=\"data row11 col8\" >0.5333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_5e285_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_5e285_row12_col1\" class=\"data row12 col1\" >0.7780</td>\n",
       "      <td id=\"T_5e285_row12_col2\" class=\"data row12 col2\" >0.6122</td>\n",
       "      <td id=\"T_5e285_row12_col3\" class=\"data row12 col3\" >0.1837</td>\n",
       "      <td id=\"T_5e285_row12_col4\" class=\"data row12 col4\" >0.4314</td>\n",
       "      <td id=\"T_5e285_row12_col5\" class=\"data row12 col5\" >0.2576</td>\n",
       "      <td id=\"T_5e285_row12_col6\" class=\"data row12 col6\" >0.1512</td>\n",
       "      <td id=\"T_5e285_row12_col7\" class=\"data row12 col7\" >0.1704</td>\n",
       "      <td id=\"T_5e285_row12_col8\" class=\"data row12 col8\" >0.6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_5e285_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_5e285_row13_col1\" class=\"data row13 col1\" >0.7904</td>\n",
       "      <td id=\"T_5e285_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_5e285_row13_col3\" class=\"data row13 col3\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row13_col4\" class=\"data row13 col4\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row13_col5\" class=\"data row13 col5\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row13_col8\" class=\"data row13 col8\" >0.2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row14\" class=\"row_heading level0 row14\" >svm</th>\n",
       "      <td id=\"T_5e285_row14_col0\" class=\"data row14 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_5e285_row14_col1\" class=\"data row14 col1\" >0.7151</td>\n",
       "      <td id=\"T_5e285_row14_col2\" class=\"data row14 col2\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row14_col3\" class=\"data row14 col3\" >0.2466</td>\n",
       "      <td id=\"T_5e285_row14_col4\" class=\"data row14 col4\" >0.2826</td>\n",
       "      <td id=\"T_5e285_row14_col5\" class=\"data row14 col5\" >0.2548</td>\n",
       "      <td id=\"T_5e285_row14_col6\" class=\"data row14 col6\" >0.0856</td>\n",
       "      <td id=\"T_5e285_row14_col7\" class=\"data row14 col7\" >0.0876</td>\n",
       "      <td id=\"T_5e285_row14_col8\" class=\"data row14 col8\" >0.4133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e285_level0_row15\" class=\"row_heading level0 row15\" >ridge</th>\n",
       "      <td id=\"T_5e285_row15_col0\" class=\"data row15 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_5e285_row15_col1\" class=\"data row15 col1\" >0.8172</td>\n",
       "      <td id=\"T_5e285_row15_col2\" class=\"data row15 col2\" >0.0000</td>\n",
       "      <td id=\"T_5e285_row15_col3\" class=\"data row15 col3\" >0.1550</td>\n",
       "      <td id=\"T_5e285_row15_col4\" class=\"data row15 col4\" >0.8528</td>\n",
       "      <td id=\"T_5e285_row15_col5\" class=\"data row15 col5\" >0.2617</td>\n",
       "      <td id=\"T_5e285_row15_col6\" class=\"data row15 col6\" >0.2111</td>\n",
       "      <td id=\"T_5e285_row15_col7\" class=\"data row15 col7\" >0.3138</td>\n",
       "      <td id=\"T_5e285_row15_col8\" class=\"data row15 col8\" >0.2167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bad818b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_3 = compare_models(sort ='AUC', fold=3, n_select = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7c50d-092f-43db-93f0-beb620a6c0dc",
   "metadata": {},
   "source": [
    "AUC 기준 Catboost, XGBoost, LightGBM이 우수한 모델로 선정되었다.\n",
    "3개 모델을 대상으로 파라미터 최적화를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff216b5-9d9d-451a-a5be-f0b775503530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812fb800-7ccf-4cea-9059-947dc63340f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_37f56_row10_col0, #T_37f56_row10_col1, #T_37f56_row10_col2, #T_37f56_row10_col3, #T_37f56_row10_col4, #T_37f56_row10_col5, #T_37f56_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_37f56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_37f56_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_37f56_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_37f56_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_37f56_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_37f56_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_37f56_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_37f56_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_37f56_row0_col0\" class=\"data row0 col0\" >0.7650</td>\n",
       "      <td id=\"T_37f56_row0_col1\" class=\"data row0 col1\" >0.6516</td>\n",
       "      <td id=\"T_37f56_row0_col2\" class=\"data row0 col2\" >0.4566</td>\n",
       "      <td id=\"T_37f56_row0_col3\" class=\"data row0 col3\" >0.4405</td>\n",
       "      <td id=\"T_37f56_row0_col4\" class=\"data row0 col4\" >0.4484</td>\n",
       "      <td id=\"T_37f56_row0_col5\" class=\"data row0 col5\" >0.2992</td>\n",
       "      <td id=\"T_37f56_row0_col6\" class=\"data row0 col6\" >0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_37f56_row1_col0\" class=\"data row1 col0\" >0.7287</td>\n",
       "      <td id=\"T_37f56_row1_col1\" class=\"data row1 col1\" >0.6169</td>\n",
       "      <td id=\"T_37f56_row1_col2\" class=\"data row1 col2\" >0.4247</td>\n",
       "      <td id=\"T_37f56_row1_col3\" class=\"data row1 col3\" >0.3705</td>\n",
       "      <td id=\"T_37f56_row1_col4\" class=\"data row1 col4\" >0.3957</td>\n",
       "      <td id=\"T_37f56_row1_col5\" class=\"data row1 col5\" >0.2219</td>\n",
       "      <td id=\"T_37f56_row1_col6\" class=\"data row1 col6\" >0.2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_37f56_row2_col0\" class=\"data row2 col0\" >0.7507</td>\n",
       "      <td id=\"T_37f56_row2_col1\" class=\"data row2 col1\" >0.6191</td>\n",
       "      <td id=\"T_37f56_row2_col2\" class=\"data row2 col2\" >0.3927</td>\n",
       "      <td id=\"T_37f56_row2_col3\" class=\"data row2 col3\" >0.4019</td>\n",
       "      <td id=\"T_37f56_row2_col4\" class=\"data row2 col4\" >0.3972</td>\n",
       "      <td id=\"T_37f56_row2_col5\" class=\"data row2 col5\" >0.2401</td>\n",
       "      <td id=\"T_37f56_row2_col6\" class=\"data row2 col6\" >0.2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_37f56_row3_col0\" class=\"data row3 col0\" >0.7507</td>\n",
       "      <td id=\"T_37f56_row3_col1\" class=\"data row3 col1\" >0.6420</td>\n",
       "      <td id=\"T_37f56_row3_col2\" class=\"data row3 col2\" >0.4545</td>\n",
       "      <td id=\"T_37f56_row3_col3\" class=\"data row3 col3\" >0.4149</td>\n",
       "      <td id=\"T_37f56_row3_col4\" class=\"data row3 col4\" >0.4338</td>\n",
       "      <td id=\"T_37f56_row3_col5\" class=\"data row3 col5\" >0.2744</td>\n",
       "      <td id=\"T_37f56_row3_col6\" class=\"data row3 col6\" >0.2749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_37f56_row4_col0\" class=\"data row4 col0\" >0.7364</td>\n",
       "      <td id=\"T_37f56_row4_col1\" class=\"data row4 col1\" >0.6380</td>\n",
       "      <td id=\"T_37f56_row4_col2\" class=\"data row4 col2\" >0.4682</td>\n",
       "      <td id=\"T_37f56_row4_col3\" class=\"data row4 col3\" >0.3931</td>\n",
       "      <td id=\"T_37f56_row4_col4\" class=\"data row4 col4\" >0.4274</td>\n",
       "      <td id=\"T_37f56_row4_col5\" class=\"data row4 col5\" >0.2579</td>\n",
       "      <td id=\"T_37f56_row4_col6\" class=\"data row4 col6\" >0.2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_37f56_row5_col0\" class=\"data row5 col0\" >0.7431</td>\n",
       "      <td id=\"T_37f56_row5_col1\" class=\"data row5 col1\" >0.6138</td>\n",
       "      <td id=\"T_37f56_row5_col2\" class=\"data row5 col2\" >0.3909</td>\n",
       "      <td id=\"T_37f56_row5_col3\" class=\"data row5 col3\" >0.3891</td>\n",
       "      <td id=\"T_37f56_row5_col4\" class=\"data row5 col4\" >0.3900</td>\n",
       "      <td id=\"T_37f56_row5_col5\" class=\"data row5 col5\" >0.2273</td>\n",
       "      <td id=\"T_37f56_row5_col6\" class=\"data row5 col6\" >0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_37f56_row6_col0\" class=\"data row6 col0\" >0.7469</td>\n",
       "      <td id=\"T_37f56_row6_col1\" class=\"data row6 col1\" >0.6213</td>\n",
       "      <td id=\"T_37f56_row6_col2\" class=\"data row6 col2\" >0.4045</td>\n",
       "      <td id=\"T_37f56_row6_col3\" class=\"data row6 col3\" >0.3991</td>\n",
       "      <td id=\"T_37f56_row6_col4\" class=\"data row6 col4\" >0.4018</td>\n",
       "      <td id=\"T_37f56_row6_col5\" class=\"data row6 col5\" >0.2413</td>\n",
       "      <td id=\"T_37f56_row6_col6\" class=\"data row6 col6\" >0.2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_37f56_row7_col0\" class=\"data row7 col0\" >0.7304</td>\n",
       "      <td id=\"T_37f56_row7_col1\" class=\"data row7 col1\" >0.6079</td>\n",
       "      <td id=\"T_37f56_row7_col2\" class=\"data row7 col2\" >0.3973</td>\n",
       "      <td id=\"T_37f56_row7_col3\" class=\"data row7 col3\" >0.3671</td>\n",
       "      <td id=\"T_37f56_row7_col4\" class=\"data row7 col4\" >0.3816</td>\n",
       "      <td id=\"T_37f56_row7_col5\" class=\"data row7 col5\" >0.2096</td>\n",
       "      <td id=\"T_37f56_row7_col6\" class=\"data row7 col6\" >0.2098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_37f56_row8_col0\" class=\"data row8 col0\" >0.7409</td>\n",
       "      <td id=\"T_37f56_row8_col1\" class=\"data row8 col1\" >0.6297</td>\n",
       "      <td id=\"T_37f56_row8_col2\" class=\"data row8 col2\" >0.4384</td>\n",
       "      <td id=\"T_37f56_row8_col3\" class=\"data row8 col3\" >0.3934</td>\n",
       "      <td id=\"T_37f56_row8_col4\" class=\"data row8 col4\" >0.4147</td>\n",
       "      <td id=\"T_37f56_row8_col5\" class=\"data row8 col5\" >0.2489</td>\n",
       "      <td id=\"T_37f56_row8_col6\" class=\"data row8 col6\" >0.2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_37f56_row9_col0\" class=\"data row9 col0\" >0.7199</td>\n",
       "      <td id=\"T_37f56_row9_col1\" class=\"data row9 col1\" >0.5946</td>\n",
       "      <td id=\"T_37f56_row9_col2\" class=\"data row9 col2\" >0.3790</td>\n",
       "      <td id=\"T_37f56_row9_col3\" class=\"data row9 col3\" >0.3458</td>\n",
       "      <td id=\"T_37f56_row9_col4\" class=\"data row9 col4\" >0.3617</td>\n",
       "      <td id=\"T_37f56_row9_col5\" class=\"data row9 col5\" >0.1827</td>\n",
       "      <td id=\"T_37f56_row9_col6\" class=\"data row9 col6\" >0.1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_37f56_row10_col0\" class=\"data row10 col0\" >0.7413</td>\n",
       "      <td id=\"T_37f56_row10_col1\" class=\"data row10 col1\" >0.6235</td>\n",
       "      <td id=\"T_37f56_row10_col2\" class=\"data row10 col2\" >0.4207</td>\n",
       "      <td id=\"T_37f56_row10_col3\" class=\"data row10 col3\" >0.3916</td>\n",
       "      <td id=\"T_37f56_row10_col4\" class=\"data row10 col4\" >0.4052</td>\n",
       "      <td id=\"T_37f56_row10_col5\" class=\"data row10 col5\" >0.2403</td>\n",
       "      <td id=\"T_37f56_row10_col6\" class=\"data row10 col6\" >0.2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37f56_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_37f56_row11_col0\" class=\"data row11 col0\" >0.0124</td>\n",
       "      <td id=\"T_37f56_row11_col1\" class=\"data row11 col1\" >0.0162</td>\n",
       "      <td id=\"T_37f56_row11_col2\" class=\"data row11 col2\" >0.0304</td>\n",
       "      <td id=\"T_37f56_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_37f56_row11_col4\" class=\"data row11 col4\" >0.0247</td>\n",
       "      <td id=\"T_37f56_row11_col5\" class=\"data row11 col5\" >0.0313</td>\n",
       "      <td id=\"T_37f56_row11_col6\" class=\"data row11 col6\" >0.0313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1769aba00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train a decision tree model\n",
    "dt = create_model('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010daa9-1a3c-4e5b-90c8-6f48ca354bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e51ed485-5abb-4260-82bb-a5a9daf80be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ab353_row10_col0, #T_ab353_row10_col1, #T_ab353_row10_col2, #T_ab353_row10_col3, #T_ab353_row10_col4, #T_ab353_row10_col5, #T_ab353_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ab353\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ab353_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_ab353_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_ab353_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_ab353_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_ab353_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_ab353_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_ab353_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ab353_row0_col0\" class=\"data row0 col0\" >0.8118</td>\n",
       "      <td id=\"T_ab353_row0_col1\" class=\"data row0 col1\" >0.7316</td>\n",
       "      <td id=\"T_ab353_row0_col2\" class=\"data row0 col2\" >0.2192</td>\n",
       "      <td id=\"T_ab353_row0_col3\" class=\"data row0 col3\" >0.6486</td>\n",
       "      <td id=\"T_ab353_row0_col4\" class=\"data row0 col4\" >0.3276</td>\n",
       "      <td id=\"T_ab353_row0_col5\" class=\"data row0 col5\" >0.2482</td>\n",
       "      <td id=\"T_ab353_row0_col6\" class=\"data row0 col6\" >0.2980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ab353_row1_col0\" class=\"data row1 col0\" >0.8157</td>\n",
       "      <td id=\"T_ab353_row1_col1\" class=\"data row1 col1\" >0.7160</td>\n",
       "      <td id=\"T_ab353_row1_col2\" class=\"data row1 col2\" >0.1370</td>\n",
       "      <td id=\"T_ab353_row1_col3\" class=\"data row1 col3\" >0.8824</td>\n",
       "      <td id=\"T_ab353_row1_col4\" class=\"data row1 col4\" >0.2372</td>\n",
       "      <td id=\"T_ab353_row1_col5\" class=\"data row1 col5\" >0.1917</td>\n",
       "      <td id=\"T_ab353_row1_col6\" class=\"data row1 col6\" >0.3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ab353_row2_col0\" class=\"data row2 col0\" >0.8109</td>\n",
       "      <td id=\"T_ab353_row2_col1\" class=\"data row2 col1\" >0.7217</td>\n",
       "      <td id=\"T_ab353_row2_col2\" class=\"data row2 col2\" >0.1233</td>\n",
       "      <td id=\"T_ab353_row2_col3\" class=\"data row2 col3\" >0.8182</td>\n",
       "      <td id=\"T_ab353_row2_col4\" class=\"data row2 col4\" >0.2143</td>\n",
       "      <td id=\"T_ab353_row2_col5\" class=\"data row2 col5\" >0.1687</td>\n",
       "      <td id=\"T_ab353_row2_col6\" class=\"data row2 col6\" >0.2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ab353_row3_col0\" class=\"data row3 col0\" >0.8214</td>\n",
       "      <td id=\"T_ab353_row3_col1\" class=\"data row3 col1\" >0.7448</td>\n",
       "      <td id=\"T_ab353_row3_col2\" class=\"data row3 col2\" >0.1591</td>\n",
       "      <td id=\"T_ab353_row3_col3\" class=\"data row3 col3\" >0.9459</td>\n",
       "      <td id=\"T_ab353_row3_col4\" class=\"data row3 col4\" >0.2724</td>\n",
       "      <td id=\"T_ab353_row3_col5\" class=\"data row3 col5\" >0.2255</td>\n",
       "      <td id=\"T_ab353_row3_col6\" class=\"data row3 col6\" >0.3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ab353_row4_col0\" class=\"data row4 col0\" >0.8290</td>\n",
       "      <td id=\"T_ab353_row4_col1\" class=\"data row4 col1\" >0.7335</td>\n",
       "      <td id=\"T_ab353_row4_col2\" class=\"data row4 col2\" >0.1955</td>\n",
       "      <td id=\"T_ab353_row4_col3\" class=\"data row4 col3\" >0.9556</td>\n",
       "      <td id=\"T_ab353_row4_col4\" class=\"data row4 col4\" >0.3245</td>\n",
       "      <td id=\"T_ab353_row4_col5\" class=\"data row4 col5\" >0.2726</td>\n",
       "      <td id=\"T_ab353_row4_col6\" class=\"data row4 col6\" >0.3878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ab353_row5_col0\" class=\"data row5 col0\" >0.8204</td>\n",
       "      <td id=\"T_ab353_row5_col1\" class=\"data row5 col1\" >0.7189</td>\n",
       "      <td id=\"T_ab353_row5_col2\" class=\"data row5 col2\" >0.2045</td>\n",
       "      <td id=\"T_ab353_row5_col3\" class=\"data row5 col3\" >0.7759</td>\n",
       "      <td id=\"T_ab353_row5_col4\" class=\"data row5 col4\" >0.3237</td>\n",
       "      <td id=\"T_ab353_row5_col5\" class=\"data row5 col5\" >0.2587</td>\n",
       "      <td id=\"T_ab353_row5_col6\" class=\"data row5 col6\" >0.3363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ab353_row6_col0\" class=\"data row6 col0\" >0.8157</td>\n",
       "      <td id=\"T_ab353_row6_col1\" class=\"data row6 col1\" >0.7387</td>\n",
       "      <td id=\"T_ab353_row6_col2\" class=\"data row6 col2\" >0.1591</td>\n",
       "      <td id=\"T_ab353_row6_col3\" class=\"data row6 col3\" >0.8140</td>\n",
       "      <td id=\"T_ab353_row6_col4\" class=\"data row6 col4\" >0.2662</td>\n",
       "      <td id=\"T_ab353_row6_col5\" class=\"data row6 col5\" >0.2120</td>\n",
       "      <td id=\"T_ab353_row6_col6\" class=\"data row6 col6\" >0.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ab353_row7_col0\" class=\"data row7 col0\" >0.8107</td>\n",
       "      <td id=\"T_ab353_row7_col1\" class=\"data row7 col1\" >0.6936</td>\n",
       "      <td id=\"T_ab353_row7_col2\" class=\"data row7 col2\" >0.2146</td>\n",
       "      <td id=\"T_ab353_row7_col3\" class=\"data row7 col3\" >0.6438</td>\n",
       "      <td id=\"T_ab353_row7_col4\" class=\"data row7 col4\" >0.3219</td>\n",
       "      <td id=\"T_ab353_row7_col5\" class=\"data row7 col5\" >0.2426</td>\n",
       "      <td id=\"T_ab353_row7_col6\" class=\"data row7 col6\" >0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ab353_row8_col0\" class=\"data row8 col0\" >0.8193</td>\n",
       "      <td id=\"T_ab353_row8_col1\" class=\"data row8 col1\" >0.7111</td>\n",
       "      <td id=\"T_ab353_row8_col2\" class=\"data row8 col2\" >0.1370</td>\n",
       "      <td id=\"T_ab353_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_ab353_row8_col4\" class=\"data row8 col4\" >0.2410</td>\n",
       "      <td id=\"T_ab353_row8_col5\" class=\"data row8 col5\" >0.2006</td>\n",
       "      <td id=\"T_ab353_row8_col6\" class=\"data row8 col6\" >0.3339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ab353_row9_col0\" class=\"data row9 col0\" >0.8069</td>\n",
       "      <td id=\"T_ab353_row9_col1\" class=\"data row9 col1\" >0.7285</td>\n",
       "      <td id=\"T_ab353_row9_col2\" class=\"data row9 col2\" >0.2146</td>\n",
       "      <td id=\"T_ab353_row9_col3\" class=\"data row9 col3\" >0.6104</td>\n",
       "      <td id=\"T_ab353_row9_col4\" class=\"data row9 col4\" >0.3176</td>\n",
       "      <td id=\"T_ab353_row9_col5\" class=\"data row9 col5\" >0.2341</td>\n",
       "      <td id=\"T_ab353_row9_col6\" class=\"data row9 col6\" >0.2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_ab353_row10_col0\" class=\"data row10 col0\" >0.8162</td>\n",
       "      <td id=\"T_ab353_row10_col1\" class=\"data row10 col1\" >0.7238</td>\n",
       "      <td id=\"T_ab353_row10_col2\" class=\"data row10 col2\" >0.1764</td>\n",
       "      <td id=\"T_ab353_row10_col3\" class=\"data row10 col3\" >0.8095</td>\n",
       "      <td id=\"T_ab353_row10_col4\" class=\"data row10 col4\" >0.2846</td>\n",
       "      <td id=\"T_ab353_row10_col5\" class=\"data row10 col5\" >0.2255</td>\n",
       "      <td id=\"T_ab353_row10_col6\" class=\"data row10 col6\" >0.3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab353_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_ab353_row11_col0\" class=\"data row11 col0\" >0.0062</td>\n",
       "      <td id=\"T_ab353_row11_col1\" class=\"data row11 col1\" >0.0141</td>\n",
       "      <td id=\"T_ab353_row11_col2\" class=\"data row11 col2\" >0.0353</td>\n",
       "      <td id=\"T_ab353_row11_col3\" class=\"data row11 col3\" >0.1326</td>\n",
       "      <td id=\"T_ab353_row11_col4\" class=\"data row11 col4\" >0.0413</td>\n",
       "      <td id=\"T_ab353_row11_col5\" class=\"data row11 col5\" >0.0306</td>\n",
       "      <td id=\"T_ab353_row11_col6\" class=\"data row11 col6\" >0.0338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bd61e670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters of decision tree\n",
    "tuned_dt = tune_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2119b94-b5d0-48c6-859a-eb7c7800a515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d7ec6f-cf7c-4b70-882b-70bd213b844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_62360_row10_col0, #T_62360_row10_col1, #T_62360_row10_col2, #T_62360_row10_col3, #T_62360_row10_col4, #T_62360_row10_col5, #T_62360_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_62360\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_62360_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_62360_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_62360_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_62360_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_62360_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_62360_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_62360_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_62360_row0_col0\" class=\"data row0 col0\" >0.8290</td>\n",
       "      <td id=\"T_62360_row0_col1\" class=\"data row0 col1\" >0.7419</td>\n",
       "      <td id=\"T_62360_row0_col2\" class=\"data row0 col2\" >0.2694</td>\n",
       "      <td id=\"T_62360_row0_col3\" class=\"data row0 col3\" >0.7564</td>\n",
       "      <td id=\"T_62360_row0_col4\" class=\"data row0 col4\" >0.3973</td>\n",
       "      <td id=\"T_62360_row0_col5\" class=\"data row0 col5\" >0.3229</td>\n",
       "      <td id=\"T_62360_row0_col6\" class=\"data row0 col6\" >0.3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_62360_row1_col0\" class=\"data row1 col0\" >0.8281</td>\n",
       "      <td id=\"T_62360_row1_col1\" class=\"data row1 col1\" >0.7227</td>\n",
       "      <td id=\"T_62360_row1_col2\" class=\"data row1 col2\" >0.2740</td>\n",
       "      <td id=\"T_62360_row1_col3\" class=\"data row1 col3\" >0.7407</td>\n",
       "      <td id=\"T_62360_row1_col4\" class=\"data row1 col4\" >0.4000</td>\n",
       "      <td id=\"T_62360_row1_col5\" class=\"data row1 col5\" >0.3236</td>\n",
       "      <td id=\"T_62360_row1_col6\" class=\"data row1 col6\" >0.3785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_62360_row2_col0\" class=\"data row2 col0\" >0.8090</td>\n",
       "      <td id=\"T_62360_row2_col1\" class=\"data row2 col1\" >0.7292</td>\n",
       "      <td id=\"T_62360_row2_col2\" class=\"data row2 col2\" >0.1963</td>\n",
       "      <td id=\"T_62360_row2_col3\" class=\"data row2 col3\" >0.6418</td>\n",
       "      <td id=\"T_62360_row2_col4\" class=\"data row2 col4\" >0.3007</td>\n",
       "      <td id=\"T_62360_row2_col5\" class=\"data row2 col5\" >0.2247</td>\n",
       "      <td id=\"T_62360_row2_col6\" class=\"data row2 col6\" >0.2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_62360_row3_col0\" class=\"data row3 col0\" >0.8262</td>\n",
       "      <td id=\"T_62360_row3_col1\" class=\"data row3 col1\" >0.7316</td>\n",
       "      <td id=\"T_62360_row3_col2\" class=\"data row3 col2\" >0.2727</td>\n",
       "      <td id=\"T_62360_row3_col3\" class=\"data row3 col3\" >0.7317</td>\n",
       "      <td id=\"T_62360_row3_col4\" class=\"data row3 col4\" >0.3974</td>\n",
       "      <td id=\"T_62360_row3_col5\" class=\"data row3 col5\" >0.3197</td>\n",
       "      <td id=\"T_62360_row3_col6\" class=\"data row3 col6\" >0.3732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_62360_row4_col0\" class=\"data row4 col0\" >0.8243</td>\n",
       "      <td id=\"T_62360_row4_col1\" class=\"data row4 col1\" >0.7432</td>\n",
       "      <td id=\"T_62360_row4_col2\" class=\"data row4 col2\" >0.2682</td>\n",
       "      <td id=\"T_62360_row4_col3\" class=\"data row4 col3\" >0.7195</td>\n",
       "      <td id=\"T_62360_row4_col4\" class=\"data row4 col4\" >0.3907</td>\n",
       "      <td id=\"T_62360_row4_col5\" class=\"data row4 col5\" >0.3123</td>\n",
       "      <td id=\"T_62360_row4_col6\" class=\"data row4 col6\" >0.3645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_62360_row5_col0\" class=\"data row5 col0\" >0.8052</td>\n",
       "      <td id=\"T_62360_row5_col1\" class=\"data row5 col1\" >0.7136</td>\n",
       "      <td id=\"T_62360_row5_col2\" class=\"data row5 col2\" >0.2000</td>\n",
       "      <td id=\"T_62360_row5_col3\" class=\"data row5 col3\" >0.6111</td>\n",
       "      <td id=\"T_62360_row5_col4\" class=\"data row5 col4\" >0.3014</td>\n",
       "      <td id=\"T_62360_row5_col5\" class=\"data row5 col5\" >0.2206</td>\n",
       "      <td id=\"T_62360_row5_col6\" class=\"data row5 col6\" >0.2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_62360_row6_col0\" class=\"data row6 col0\" >0.8271</td>\n",
       "      <td id=\"T_62360_row6_col1\" class=\"data row6 col1\" >0.7324</td>\n",
       "      <td id=\"T_62360_row6_col2\" class=\"data row6 col2\" >0.2545</td>\n",
       "      <td id=\"T_62360_row6_col3\" class=\"data row6 col3\" >0.7671</td>\n",
       "      <td id=\"T_62360_row6_col4\" class=\"data row6 col4\" >0.3823</td>\n",
       "      <td id=\"T_62360_row6_col5\" class=\"data row6 col5\" >0.3100</td>\n",
       "      <td id=\"T_62360_row6_col6\" class=\"data row6 col6\" >0.3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_62360_row7_col0\" class=\"data row7 col0\" >0.8212</td>\n",
       "      <td id=\"T_62360_row7_col1\" class=\"data row7 col1\" >0.7179</td>\n",
       "      <td id=\"T_62360_row7_col2\" class=\"data row7 col2\" >0.2329</td>\n",
       "      <td id=\"T_62360_row7_col3\" class=\"data row7 col3\" >0.7286</td>\n",
       "      <td id=\"T_62360_row7_col4\" class=\"data row7 col4\" >0.3529</td>\n",
       "      <td id=\"T_62360_row7_col5\" class=\"data row7 col5\" >0.2799</td>\n",
       "      <td id=\"T_62360_row7_col6\" class=\"data row7 col6\" >0.3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_62360_row8_col0\" class=\"data row8 col0\" >0.8317</td>\n",
       "      <td id=\"T_62360_row8_col1\" class=\"data row8 col1\" >0.7042</td>\n",
       "      <td id=\"T_62360_row8_col2\" class=\"data row8 col2\" >0.2557</td>\n",
       "      <td id=\"T_62360_row8_col3\" class=\"data row8 col3\" >0.8116</td>\n",
       "      <td id=\"T_62360_row8_col4\" class=\"data row8 col4\" >0.3889</td>\n",
       "      <td id=\"T_62360_row8_col5\" class=\"data row8 col5\" >0.3207</td>\n",
       "      <td id=\"T_62360_row8_col6\" class=\"data row8 col6\" >0.3934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_62360_row9_col0\" class=\"data row9 col0\" >0.8203</td>\n",
       "      <td id=\"T_62360_row9_col1\" class=\"data row9 col1\" >0.7344</td>\n",
       "      <td id=\"T_62360_row9_col2\" class=\"data row9 col2\" >0.2283</td>\n",
       "      <td id=\"T_62360_row9_col3\" class=\"data row9 col3\" >0.7246</td>\n",
       "      <td id=\"T_62360_row9_col4\" class=\"data row9 col4\" >0.3472</td>\n",
       "      <td id=\"T_62360_row9_col5\" class=\"data row9 col5\" >0.2744</td>\n",
       "      <td id=\"T_62360_row9_col6\" class=\"data row9 col6\" >0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_62360_row10_col0\" class=\"data row10 col0\" >0.8222</td>\n",
       "      <td id=\"T_62360_row10_col1\" class=\"data row10 col1\" >0.7271</td>\n",
       "      <td id=\"T_62360_row10_col2\" class=\"data row10 col2\" >0.2452</td>\n",
       "      <td id=\"T_62360_row10_col3\" class=\"data row10 col3\" >0.7233</td>\n",
       "      <td id=\"T_62360_row10_col4\" class=\"data row10 col4\" >0.3659</td>\n",
       "      <td id=\"T_62360_row10_col5\" class=\"data row10 col5\" >0.2909</td>\n",
       "      <td id=\"T_62360_row10_col6\" class=\"data row10 col6\" >0.3489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62360_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_62360_row11_col0\" class=\"data row11 col0\" >0.0083</td>\n",
       "      <td id=\"T_62360_row11_col1\" class=\"data row11 col1\" >0.0118</td>\n",
       "      <td id=\"T_62360_row11_col2\" class=\"data row11 col2\" >0.0279</td>\n",
       "      <td id=\"T_62360_row11_col3\" class=\"data row11 col3\" >0.0552</td>\n",
       "      <td id=\"T_62360_row11_col4\" class=\"data row11 col4\" >0.0367</td>\n",
       "      <td id=\"T_62360_row11_col5\" class=\"data row11 col5\" >0.0379</td>\n",
       "      <td id=\"T_62360_row11_col6\" class=\"data row11 col6\" >0.0415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2be6df970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters with increased n_iter\n",
    "tuned_dt1 = tune_model(dt, n_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efd275-7969-460f-a19f-056a1d8df90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d9d64fd-ceb4-4284-9dca-ebd8e21002b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4dacf_row10_col0, #T_4dacf_row10_col1, #T_4dacf_row10_col2, #T_4dacf_row10_col3, #T_4dacf_row10_col4, #T_4dacf_row10_col5, #T_4dacf_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4dacf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4dacf_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_4dacf_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_4dacf_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_4dacf_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_4dacf_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_4dacf_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_4dacf_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4dacf_row0_col0\" class=\"data row0 col0\" >0.8118</td>\n",
       "      <td id=\"T_4dacf_row0_col1\" class=\"data row0 col1\" >0.7316</td>\n",
       "      <td id=\"T_4dacf_row0_col2\" class=\"data row0 col2\" >0.2192</td>\n",
       "      <td id=\"T_4dacf_row0_col3\" class=\"data row0 col3\" >0.6486</td>\n",
       "      <td id=\"T_4dacf_row0_col4\" class=\"data row0 col4\" >0.3276</td>\n",
       "      <td id=\"T_4dacf_row0_col5\" class=\"data row0 col5\" >0.2482</td>\n",
       "      <td id=\"T_4dacf_row0_col6\" class=\"data row0 col6\" >0.2980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4dacf_row1_col0\" class=\"data row1 col0\" >0.8157</td>\n",
       "      <td id=\"T_4dacf_row1_col1\" class=\"data row1 col1\" >0.7160</td>\n",
       "      <td id=\"T_4dacf_row1_col2\" class=\"data row1 col2\" >0.1370</td>\n",
       "      <td id=\"T_4dacf_row1_col3\" class=\"data row1 col3\" >0.8824</td>\n",
       "      <td id=\"T_4dacf_row1_col4\" class=\"data row1 col4\" >0.2372</td>\n",
       "      <td id=\"T_4dacf_row1_col5\" class=\"data row1 col5\" >0.1917</td>\n",
       "      <td id=\"T_4dacf_row1_col6\" class=\"data row1 col6\" >0.3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4dacf_row2_col0\" class=\"data row2 col0\" >0.8109</td>\n",
       "      <td id=\"T_4dacf_row2_col1\" class=\"data row2 col1\" >0.7217</td>\n",
       "      <td id=\"T_4dacf_row2_col2\" class=\"data row2 col2\" >0.1233</td>\n",
       "      <td id=\"T_4dacf_row2_col3\" class=\"data row2 col3\" >0.8182</td>\n",
       "      <td id=\"T_4dacf_row2_col4\" class=\"data row2 col4\" >0.2143</td>\n",
       "      <td id=\"T_4dacf_row2_col5\" class=\"data row2 col5\" >0.1687</td>\n",
       "      <td id=\"T_4dacf_row2_col6\" class=\"data row2 col6\" >0.2701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4dacf_row3_col0\" class=\"data row3 col0\" >0.8214</td>\n",
       "      <td id=\"T_4dacf_row3_col1\" class=\"data row3 col1\" >0.7448</td>\n",
       "      <td id=\"T_4dacf_row3_col2\" class=\"data row3 col2\" >0.1591</td>\n",
       "      <td id=\"T_4dacf_row3_col3\" class=\"data row3 col3\" >0.9459</td>\n",
       "      <td id=\"T_4dacf_row3_col4\" class=\"data row3 col4\" >0.2724</td>\n",
       "      <td id=\"T_4dacf_row3_col5\" class=\"data row3 col5\" >0.2255</td>\n",
       "      <td id=\"T_4dacf_row3_col6\" class=\"data row3 col6\" >0.3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4dacf_row4_col0\" class=\"data row4 col0\" >0.8290</td>\n",
       "      <td id=\"T_4dacf_row4_col1\" class=\"data row4 col1\" >0.7335</td>\n",
       "      <td id=\"T_4dacf_row4_col2\" class=\"data row4 col2\" >0.1955</td>\n",
       "      <td id=\"T_4dacf_row4_col3\" class=\"data row4 col3\" >0.9556</td>\n",
       "      <td id=\"T_4dacf_row4_col4\" class=\"data row4 col4\" >0.3245</td>\n",
       "      <td id=\"T_4dacf_row4_col5\" class=\"data row4 col5\" >0.2726</td>\n",
       "      <td id=\"T_4dacf_row4_col6\" class=\"data row4 col6\" >0.3878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4dacf_row5_col0\" class=\"data row5 col0\" >0.8204</td>\n",
       "      <td id=\"T_4dacf_row5_col1\" class=\"data row5 col1\" >0.7189</td>\n",
       "      <td id=\"T_4dacf_row5_col2\" class=\"data row5 col2\" >0.2045</td>\n",
       "      <td id=\"T_4dacf_row5_col3\" class=\"data row5 col3\" >0.7759</td>\n",
       "      <td id=\"T_4dacf_row5_col4\" class=\"data row5 col4\" >0.3237</td>\n",
       "      <td id=\"T_4dacf_row5_col5\" class=\"data row5 col5\" >0.2587</td>\n",
       "      <td id=\"T_4dacf_row5_col6\" class=\"data row5 col6\" >0.3363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4dacf_row6_col0\" class=\"data row6 col0\" >0.8157</td>\n",
       "      <td id=\"T_4dacf_row6_col1\" class=\"data row6 col1\" >0.7387</td>\n",
       "      <td id=\"T_4dacf_row6_col2\" class=\"data row6 col2\" >0.1591</td>\n",
       "      <td id=\"T_4dacf_row6_col3\" class=\"data row6 col3\" >0.8140</td>\n",
       "      <td id=\"T_4dacf_row6_col4\" class=\"data row6 col4\" >0.2662</td>\n",
       "      <td id=\"T_4dacf_row6_col5\" class=\"data row6 col5\" >0.2120</td>\n",
       "      <td id=\"T_4dacf_row6_col6\" class=\"data row6 col6\" >0.3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4dacf_row7_col0\" class=\"data row7 col0\" >0.8107</td>\n",
       "      <td id=\"T_4dacf_row7_col1\" class=\"data row7 col1\" >0.6936</td>\n",
       "      <td id=\"T_4dacf_row7_col2\" class=\"data row7 col2\" >0.2146</td>\n",
       "      <td id=\"T_4dacf_row7_col3\" class=\"data row7 col3\" >0.6438</td>\n",
       "      <td id=\"T_4dacf_row7_col4\" class=\"data row7 col4\" >0.3219</td>\n",
       "      <td id=\"T_4dacf_row7_col5\" class=\"data row7 col5\" >0.2426</td>\n",
       "      <td id=\"T_4dacf_row7_col6\" class=\"data row7 col6\" >0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4dacf_row8_col0\" class=\"data row8 col0\" >0.8193</td>\n",
       "      <td id=\"T_4dacf_row8_col1\" class=\"data row8 col1\" >0.7111</td>\n",
       "      <td id=\"T_4dacf_row8_col2\" class=\"data row8 col2\" >0.1370</td>\n",
       "      <td id=\"T_4dacf_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_4dacf_row8_col4\" class=\"data row8 col4\" >0.2410</td>\n",
       "      <td id=\"T_4dacf_row8_col5\" class=\"data row8 col5\" >0.2006</td>\n",
       "      <td id=\"T_4dacf_row8_col6\" class=\"data row8 col6\" >0.3339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4dacf_row9_col0\" class=\"data row9 col0\" >0.8069</td>\n",
       "      <td id=\"T_4dacf_row9_col1\" class=\"data row9 col1\" >0.7285</td>\n",
       "      <td id=\"T_4dacf_row9_col2\" class=\"data row9 col2\" >0.2146</td>\n",
       "      <td id=\"T_4dacf_row9_col3\" class=\"data row9 col3\" >0.6104</td>\n",
       "      <td id=\"T_4dacf_row9_col4\" class=\"data row9 col4\" >0.3176</td>\n",
       "      <td id=\"T_4dacf_row9_col5\" class=\"data row9 col5\" >0.2341</td>\n",
       "      <td id=\"T_4dacf_row9_col6\" class=\"data row9 col6\" >0.2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_4dacf_row10_col0\" class=\"data row10 col0\" >0.8162</td>\n",
       "      <td id=\"T_4dacf_row10_col1\" class=\"data row10 col1\" >0.7238</td>\n",
       "      <td id=\"T_4dacf_row10_col2\" class=\"data row10 col2\" >0.1764</td>\n",
       "      <td id=\"T_4dacf_row10_col3\" class=\"data row10 col3\" >0.8095</td>\n",
       "      <td id=\"T_4dacf_row10_col4\" class=\"data row10 col4\" >0.2846</td>\n",
       "      <td id=\"T_4dacf_row10_col5\" class=\"data row10 col5\" >0.2255</td>\n",
       "      <td id=\"T_4dacf_row10_col6\" class=\"data row10 col6\" >0.3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dacf_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_4dacf_row11_col0\" class=\"data row11 col0\" >0.0062</td>\n",
       "      <td id=\"T_4dacf_row11_col1\" class=\"data row11 col1\" >0.0141</td>\n",
       "      <td id=\"T_4dacf_row11_col2\" class=\"data row11 col2\" >0.0353</td>\n",
       "      <td id=\"T_4dacf_row11_col3\" class=\"data row11 col3\" >0.1326</td>\n",
       "      <td id=\"T_4dacf_row11_col4\" class=\"data row11 col4\" >0.0413</td>\n",
       "      <td id=\"T_4dacf_row11_col5\" class=\"data row11 col5\" >0.0306</td>\n",
       "      <td id=\"T_4dacf_row11_col6\" class=\"data row11 col6\" >0.0338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bbf14d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters to optimize AUC\n",
    "tuned_dt2 = tune_model(dt, optimize = 'AUC') #default is 'Accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a17078-de15-477c-95d1-355a62503d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45b121-c70d-4eae-87ed-56ea308261c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05076288-fdbe-4b33-9079-a7c08af89584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b39af_row10_col0, #T_b39af_row10_col1, #T_b39af_row10_col2, #T_b39af_row10_col3, #T_b39af_row10_col4, #T_b39af_row10_col5, #T_b39af_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b39af\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b39af_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_b39af_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_b39af_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b39af_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_b39af_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_b39af_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_b39af_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b39af_row0_col0\" class=\"data row0 col0\" >0.8118</td>\n",
       "      <td id=\"T_b39af_row0_col1\" class=\"data row0 col1\" >0.7445</td>\n",
       "      <td id=\"T_b39af_row0_col2\" class=\"data row0 col2\" >0.2466</td>\n",
       "      <td id=\"T_b39af_row0_col3\" class=\"data row0 col3\" >0.6279</td>\n",
       "      <td id=\"T_b39af_row0_col4\" class=\"data row0 col4\" >0.3541</td>\n",
       "      <td id=\"T_b39af_row0_col5\" class=\"data row0 col5\" >0.2677</td>\n",
       "      <td id=\"T_b39af_row0_col6\" class=\"data row0 col6\" >0.3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b39af_row1_col0\" class=\"data row1 col0\" >0.8147</td>\n",
       "      <td id=\"T_b39af_row1_col1\" class=\"data row1 col1\" >0.7336</td>\n",
       "      <td id=\"T_b39af_row1_col2\" class=\"data row1 col2\" >0.2329</td>\n",
       "      <td id=\"T_b39af_row1_col3\" class=\"data row1 col3\" >0.6623</td>\n",
       "      <td id=\"T_b39af_row1_col4\" class=\"data row1 col4\" >0.3446</td>\n",
       "      <td id=\"T_b39af_row1_col5\" class=\"data row1 col5\" >0.2646</td>\n",
       "      <td id=\"T_b39af_row1_col6\" class=\"data row1 col6\" >0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b39af_row2_col0\" class=\"data row2 col0\" >0.8138</td>\n",
       "      <td id=\"T_b39af_row2_col1\" class=\"data row2 col1\" >0.7251</td>\n",
       "      <td id=\"T_b39af_row2_col2\" class=\"data row2 col2\" >0.1553</td>\n",
       "      <td id=\"T_b39af_row2_col3\" class=\"data row2 col3\" >0.7727</td>\n",
       "      <td id=\"T_b39af_row2_col4\" class=\"data row2 col4\" >0.2586</td>\n",
       "      <td id=\"T_b39af_row2_col5\" class=\"data row2 col5\" >0.2028</td>\n",
       "      <td id=\"T_b39af_row2_col6\" class=\"data row2 col6\" >0.2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b39af_row3_col0\" class=\"data row3 col0\" >0.8243</td>\n",
       "      <td id=\"T_b39af_row3_col1\" class=\"data row3 col1\" >0.7292</td>\n",
       "      <td id=\"T_b39af_row3_col2\" class=\"data row3 col2\" >0.2318</td>\n",
       "      <td id=\"T_b39af_row3_col3\" class=\"data row3 col3\" >0.7727</td>\n",
       "      <td id=\"T_b39af_row3_col4\" class=\"data row3 col4\" >0.3566</td>\n",
       "      <td id=\"T_b39af_row3_col5\" class=\"data row3 col5\" >0.2875</td>\n",
       "      <td id=\"T_b39af_row3_col6\" class=\"data row3 col6\" >0.3582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b39af_row4_col0\" class=\"data row4 col0\" >0.8176</td>\n",
       "      <td id=\"T_b39af_row4_col1\" class=\"data row4 col1\" >0.7270</td>\n",
       "      <td id=\"T_b39af_row4_col2\" class=\"data row4 col2\" >0.2455</td>\n",
       "      <td id=\"T_b39af_row4_col3\" class=\"data row4 col3\" >0.6835</td>\n",
       "      <td id=\"T_b39af_row4_col4\" class=\"data row4 col4\" >0.3612</td>\n",
       "      <td id=\"T_b39af_row4_col5\" class=\"data row4 col5\" >0.2814</td>\n",
       "      <td id=\"T_b39af_row4_col6\" class=\"data row4 col6\" >0.3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b39af_row5_col0\" class=\"data row5 col0\" >0.8176</td>\n",
       "      <td id=\"T_b39af_row5_col1\" class=\"data row5 col1\" >0.7130</td>\n",
       "      <td id=\"T_b39af_row5_col2\" class=\"data row5 col2\" >0.2136</td>\n",
       "      <td id=\"T_b39af_row5_col3\" class=\"data row5 col3\" >0.7231</td>\n",
       "      <td id=\"T_b39af_row5_col4\" class=\"data row5 col4\" >0.3298</td>\n",
       "      <td id=\"T_b39af_row5_col5\" class=\"data row5 col5\" >0.2588</td>\n",
       "      <td id=\"T_b39af_row5_col6\" class=\"data row5 col6\" >0.3239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b39af_row6_col0\" class=\"data row6 col0\" >0.8166</td>\n",
       "      <td id=\"T_b39af_row6_col1\" class=\"data row6 col1\" >0.7465</td>\n",
       "      <td id=\"T_b39af_row6_col2\" class=\"data row6 col2\" >0.2045</td>\n",
       "      <td id=\"T_b39af_row6_col3\" class=\"data row6 col3\" >0.7258</td>\n",
       "      <td id=\"T_b39af_row6_col4\" class=\"data row6 col4\" >0.3191</td>\n",
       "      <td id=\"T_b39af_row6_col5\" class=\"data row6 col5\" >0.2498</td>\n",
       "      <td id=\"T_b39af_row6_col6\" class=\"data row6 col6\" >0.3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b39af_row7_col0\" class=\"data row7 col0\" >0.8155</td>\n",
       "      <td id=\"T_b39af_row7_col1\" class=\"data row7 col1\" >0.6952</td>\n",
       "      <td id=\"T_b39af_row7_col2\" class=\"data row7 col2\" >0.2420</td>\n",
       "      <td id=\"T_b39af_row7_col3\" class=\"data row7 col3\" >0.6625</td>\n",
       "      <td id=\"T_b39af_row7_col4\" class=\"data row7 col4\" >0.3545</td>\n",
       "      <td id=\"T_b39af_row7_col5\" class=\"data row7 col5\" >0.2731</td>\n",
       "      <td id=\"T_b39af_row7_col6\" class=\"data row7 col6\" >0.3205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b39af_row8_col0\" class=\"data row8 col0\" >0.8270</td>\n",
       "      <td id=\"T_b39af_row8_col1\" class=\"data row8 col1\" >0.7081</td>\n",
       "      <td id=\"T_b39af_row8_col2\" class=\"data row8 col2\" >0.2283</td>\n",
       "      <td id=\"T_b39af_row8_col3\" class=\"data row8 col3\" >0.8065</td>\n",
       "      <td id=\"T_b39af_row8_col4\" class=\"data row8 col4\" >0.3559</td>\n",
       "      <td id=\"T_b39af_row8_col5\" class=\"data row8 col5\" >0.2903</td>\n",
       "      <td id=\"T_b39af_row8_col6\" class=\"data row8 col6\" >0.3684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b39af_row9_col0\" class=\"data row9 col0\" >0.8145</td>\n",
       "      <td id=\"T_b39af_row9_col1\" class=\"data row9 col1\" >0.7200</td>\n",
       "      <td id=\"T_b39af_row9_col2\" class=\"data row9 col2\" >0.2694</td>\n",
       "      <td id=\"T_b39af_row9_col3\" class=\"data row9 col3\" >0.6344</td>\n",
       "      <td id=\"T_b39af_row9_col4\" class=\"data row9 col4\" >0.3782</td>\n",
       "      <td id=\"T_b39af_row9_col5\" class=\"data row9 col5\" >0.2895</td>\n",
       "      <td id=\"T_b39af_row9_col6\" class=\"data row9 col6\" >0.3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_b39af_row10_col0\" class=\"data row10 col0\" >0.8173</td>\n",
       "      <td id=\"T_b39af_row10_col1\" class=\"data row10 col1\" >0.7242</td>\n",
       "      <td id=\"T_b39af_row10_col2\" class=\"data row10 col2\" >0.2270</td>\n",
       "      <td id=\"T_b39af_row10_col3\" class=\"data row10 col3\" >0.7071</td>\n",
       "      <td id=\"T_b39af_row10_col4\" class=\"data row10 col4\" >0.3413</td>\n",
       "      <td id=\"T_b39af_row10_col5\" class=\"data row10 col5\" >0.2666</td>\n",
       "      <td id=\"T_b39af_row10_col6\" class=\"data row10 col6\" >0.3259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b39af_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_b39af_row11_col0\" class=\"data row11 col0\" >0.0045</td>\n",
       "      <td id=\"T_b39af_row11_col1\" class=\"data row11 col1\" >0.0151</td>\n",
       "      <td id=\"T_b39af_row11_col2\" class=\"data row11 col2\" >0.0294</td>\n",
       "      <td id=\"T_b39af_row11_col3\" class=\"data row11 col3\" >0.0593</td>\n",
       "      <td id=\"T_b39af_row11_col4\" class=\"data row11 col4\" >0.0317</td>\n",
       "      <td id=\"T_b39af_row11_col5\" class=\"data row11 col5\" >0.0249</td>\n",
       "      <td id=\"T_b39af_row11_col6\" class=\"data row11 col6\" >0.0217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bbf1cee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters with custom_grid\n",
    "params = {\"max_depth\": np.random.randint(1, (len(data.columns)*.85),20),\n",
    "          \"max_features\": np.random.randint(1, len(data.columns),20),\n",
    "          \"min_samples_leaf\": [2,3,4,5,6],\n",
    "          \"criterion\": [\"gini\", \"entropy\"]\n",
    "          }\n",
    "\n",
    "tuned_dt_custom = tune_model(dt, custom_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757eca1-d904-4b24-a7aa-66620bc86121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7a190-97ad-4415-b627-4fd5141f5cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df3a386f-3a3e-4793-a6fe-18536b16d51a",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 최적화: 그리드서치(Grid Search)\n",
    "아래와 같은 과정으로 그리드서치 하이퍼파라미터 최적화를 진행한다.\n",
    "\n",
    "과거 데이터가 학습된 모델을 통해 현 시점의 대출 사기 여부를 예측하는 현업 방식과 유사하도록 아래와 같은 데이터셋을 구성한다.\n",
    "\n",
    "최적의 하이퍼파라미터 탐색: 학습(2017년 이전 데이터) / 평가(2017년 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f38e57d-2e54-422f-a850-4bc5c554855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b4528-1407-4dd3-a417-86d1e38126c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "380d59af-8e5b-44a2-be24-e97d636aa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_read1 = '/Users/a06411/Documents/data_hub/lending_club/feature_selected_ld_1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1a6367a-d03b-42de-b783-1c7160e7a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.read_pickle(path_read1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c916014f-e4fd-4d3e-99f7-128041987458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382351, 61)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aec1b8d8-84c9-441e-83c1-bc692fcab31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['int_rate', 'dti', 'annual_inc', 'mo_sin_old_rev_tl_op',\n",
       "       'acc_open_past_24mths', 'loan_amnt', 'emp_length', 'revol_bal', 'term',\n",
       "       'funded_amnt_inv', 'installment', 'purpose', 'total_rev_hi_lim',\n",
       "       'fico_range_low', 'debt_settlement_flag', 'mort_acc', 'total_bc_limit',\n",
       "       'home_ownership', 'avg_cur_bal', 'all_util', 'mths_since_recent_bc',\n",
       "       'total_acc', 'open_acc_6m', 'bc_util', 'num_actv_rev_tl', 'funded_amnt',\n",
       "       'hardship_flag', 'num_rev_tl_bal_gt_0', 'mths_since_recent_inq',\n",
       "       'inq_last_6mths', 'num_il_tl', 'mo_sin_old_il_acct', 'num_rev_accts',\n",
       "       'num_tl_120dpd_2m', 'total_il_high_credit_limit', 'application_type',\n",
       "       'revol_util', 'tot_hi_cred_lim', 'delinq_2yrs', 'mo_sin_rcnt_tl',\n",
       "       'num_actv_bc_tl', 'mths_since_last_record', 'percent_bc_gt_75',\n",
       "       'bc_open_to_buy', 'max_bal_bc', 'grade', 'open_rv_24m',\n",
       "       'mo_sin_rcnt_rev_tl_op', 'pct_tl_nvr_dlq', 'verification_status',\n",
       "       'tot_cur_bal', 'total_bal_ex_mort', 'mths_since_last_major_derog',\n",
       "       'inq_fi', 'mths_since_rcnt_il', 'inq_last_12m',\n",
       "       'mths_since_last_delinq', 'num_bc_tl', 'loan_status', 'issue_d', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f0e08-c7b3-4af0-9f3f-249ef3f439c7",
   "metadata": {},
   "source": [
    "## 모델 성능 평가용 데이터\n",
    "최적화된 하이퍼파라미터를 적용해 최종 모델 성능 지표를 산출할 데이터를 분리한다.\n",
    "\n",
    "학습(2007~2018) / 평가(2018)\n",
    "대출 신청 연도 추출:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbf31d28-8647-4d70-b3cb-64e4237d475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['issue_d'] = pd.to_datetime(df_f['issue_d'])\n",
    "df_f['issue_year'] = df_f['issue_d'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d36905b-1f16-466a-b455-e5d793b6e6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382351, 62)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45229e73-b279-41a8-92e4-9db975065808",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_f[df_f['issue_year'] != 2018]\n",
    "test = df_f[df_f['issue_year'] == 2018]\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "answer = test['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8586ae74-d83c-4ac9-9031-cf67c804591b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314290, 62)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acc2c2f2-0b66-426b-88e3-ca62c0a7f8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68061, 62)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01abd7-9afa-44d6-b077-6e5a711db7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32a39d90-72b4-4c39-b1bd-b7dd8e07514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1314290, 61)\n",
      "(1314290,)\n"
     ]
    }
   ],
   "source": [
    "X = train.copy()\n",
    "y = train['loan_status']\n",
    "\n",
    "X.drop(['loan_status'], axis = 1, inplace = True)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f4430-cb80-4ad8-9521-cd577bd878da",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 탐색용 데이터\n",
    "그리드서치(Grid Search)기법으로 하이퍼파라미터 최적화를 진행할 데이터를 분리한다.\n",
    "\n",
    "학습(2007~2017) / 검증(2017)\n",
    "학습/검증 데이터 분리:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fedf6f63-5a8f-424e-86e5-dee3a3bf7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = train[train['issue_year'] != 2017]\n",
    "ttest = train[train['issue_year'] == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ce4a633-b7b0-4daa-89d3-7c0e85acc6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1132562, 62), (181728, 62))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttrain.shape, ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3ec92-c22d-46cc-839d-5f86dc410971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ff68c-2619-4532-b4ed-f71cc3785f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ea70d1-2bc7-49c8-a2f8-6a6aed7c9686",
   "metadata": {},
   "source": [
    "## 데이터 내 독립변수(X_train, X_test) / 종속변수(y_train, y_test) 분리:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19984421-1f38-40b8-86d9-b44b059c5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ttrain.copy()\n",
    "y_train = ttrain['loan_status']\n",
    "X_train.drop(['loan_status'], axis = 1, inplace = True)\n",
    "\n",
    "X_test = ttest.copy()\n",
    "y_test = ttest['loan_status']\n",
    "X_test.drop(['loan_status'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1ac5b-7faa-4321-b772-6df3cae19d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2e73a45-415b-4c62-acae-35df2b36131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['earliest_cr_line', 'issue_d', 'last_credit_pull_d', \n",
    "                   'last_pymnt_d', 'next_pymnt_d',\n",
    "                  'initial_list_status','out_prncp','out_prncp_inv',\n",
    "                   'total_pymnt','total_pymnt_inv','total_rec_prncp',\n",
    "                   'total_rec_int','total_rec_late_fee',\n",
    "                   'recoveries','collection_recovery_fee','last_pymnt_amnt',\n",
    "                   'last_fico_range_high','last_fico_range_low' , \n",
    "                   'id', 'loan_status' , 'issue_year',\n",
    "                   'addr_state','sub_grade' ]\n",
    "features  = [col for col in list(train) if col not in remove_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc2bb8-4dc8-4ce2-b7be-874320850989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "513570f3-a5e3-438c-9e79-c4fc0dfec1c4",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 최적화(Grid Search)\n",
    "아래와 같은 과정으로 그리드서치 하이퍼파라미터 최적화를 진행한다.\n",
    "\n",
    "하이퍼파라미터 초기값 지정\n",
    "하이퍼파라미터 별 탐색 범위 지정\n",
    "그리드 서치 후 최적값 저장\n",
    "하이퍼파라미터 초기값 지정:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68c53eb9-12f9-4374-9aa9-cbd2eac985b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'subsample', 'subsample_for_bin', 'subsample_freq', 'silent', 'max_bin'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'application': 'binary',\n",
    "    'boosting': 'gbdt', \n",
    "    'num_iterations': 100, \n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 62,\n",
    "    'max_depth': -1,\n",
    "    'max_bin': 510, \n",
    "    'lambda_l1': 5, \n",
    "    'lambda_l2': 10, \n",
    "    'metric' : 'binary_error',\n",
    "    'subsample_for_bin': 200,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.8, \n",
    "    'min_split_gain': 0.5, \n",
    "    'min_child_weight': 1, \n",
    "    'min_child_samples': 5\n",
    "}\n",
    "\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
    "          objective = 'binary', \n",
    "          n_jobs = 5, \n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'], \n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'], \n",
    "          min_split_gain = params['min_split_gain'], \n",
    "          min_child_weight = params['min_child_weight'], \n",
    "          min_child_samples = params['min_child_samples'])\n",
    "\n",
    "mdl.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed549275-0c36-420a-884e-94c8a5362b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "979cc7c1-2073-4df6-b48b-f35f334aa9ff",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 별 탐색 범위 지정:\n",
    "\n",
    "- bagging_fraction: 데이터의 일부만 사용하는 bagging의 비율\n",
    "- learning_rate: 학습 gradient에 부여하는 가중치\n",
    "- num_leaves: 예측 트리에서 데이터가 분기되는 가지의 수\n",
    "- max_depth: 에측 트리의 최대 깊이\n",
    "- reg_alpha: L1 정규화 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b88e38b0-57f8-4971-8153-2323df049f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'bagging_fraction': [0.6, 0.8],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves': [125, 255],\n",
    "    'max_depth': [10,20],\n",
    "    'reg_alpha' : [0.5,1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a874ed-adbb-4b41-a5b9-5fd1297986a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40fabac7-47c6-4d32-bdf6-b84b5f557d22",
   "metadata": {},
   "source": [
    "## 그리드 서치:\n",
    "\n",
    "- 학습 데이터: X_train, y_train(2007~2017)\n",
    "- 검증 데이터: X_test, y_test(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b18c45-b494-41bc-8d28-ad6dd042ed0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a72b983b-4f20-44c2-9616-e3d2a69091ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 32 candidates, totalling 128 fits\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.242484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.377500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 228813, number of negative: 903749\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1702\n",
      "[LightGBM] [Info] Number of data points in the train set: 1132562, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373647\n",
      "[LightGBM] [Info] Start training from score -1.373647\n",
      "{'bagging_fraction': 0.6, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 125, 'reg_alpha': 0.5}\n",
      "0.8261101735133024\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.158691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.149136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.217860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.158709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.250403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.319924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.146677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.186418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.210068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.156009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.179982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.214961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.231672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.241587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.299974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.212068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.187105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.288579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.337567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.233902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.155110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.175539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677811\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.232436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1753\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 57\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202032 -> initscore=-1.373644\n",
      "[LightGBM] [Info] Start training from score -1.373644\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171609, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849421, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373651\n",
      "[LightGBM] [Info] Start training from score -1.373651\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 171610, number of negative: 677812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1692\n",
      "[LightGBM] [Info] Number of data points in the train set: 849422, number of used features: 56\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202031 -> initscore=-1.373646\n",
      "[LightGBM] [Info] Start training from score -1.373646\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    }
   ],
   "source": [
    "gridParams = {\n",
    "    'bagging_fraction': [0.6, 0.8],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves': [125, 255],\n",
    "    'max_depth': [10,20],\n",
    "    'reg_alpha' : [0.5,1]\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train[features], y_train, eval_metric='auc',\n",
    "         eval_set=[(X_train[features], y_train), (X_test[features], y_test)])\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3727edc-7582-4388-ab2a-f5b62d9f9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.6, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 125, 'reg_alpha': 0.5}\n",
      "0.8261101735133024\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04044fa2-4ef3-4ee5-8fd9-b024c4ff15a9",
   "metadata": {},
   "source": [
    "## 최적의 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d73bb96-8d99-404f-aeca-bc1e81f88807",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['bagging_fraction'] = grid.best_params_['bagging_fraction']\n",
    "params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "params['max_depth'] = grid.best_params_['max_depth']\n",
    "params['reg_alpha'] = grid.best_params_['reg_alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92419c0a-1854-4f89-a5e4-cc2af12bc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3749e49-4ea8-4885-9f39-33f919feb036",
   "metadata": {},
   "source": [
    "# 예측 및 성능 평가 함수:\n",
    "\n",
    "k-fold 교차검증을 통한 과적합 이슈 방지\n",
    "하이퍼파라미터 최적값 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d4bdda9-91e3-4c8f-bb83-49d5f858106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lgb_prediction(train, y, test, features, categorical_features='auto', model_params=None, folds=5):\n",
    "    \n",
    "    skf = KFold(n_splits=folds, random_state=SEED, shuffle=True)\n",
    "    folds = 5\n",
    "    x_train = train[features]\n",
    "    x_test = test[features]\n",
    "\n",
    "    y_preds = np.zeros(x_test.shape[0])\n",
    "    y_oof = np.zeros(x_train.shape[0])\n",
    "    score = 0    \n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(x_train, y)):\n",
    "        print(f'Fold: {fold+1}')\n",
    "\n",
    "        x_tr, x_val = x_train.loc[tr_idx, features], x_train.loc[val_idx, features]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        print(x_tr.shape, x_val.shape)\n",
    "\n",
    "        dtrain = lgb.Dataset(x_tr, label=y_tr)\n",
    "        dvalid = lgb.Dataset(x_val, label=y_val)\n",
    "\n",
    "        clf = lgb.train(   \n",
    "            model_params,\n",
    "            dtrain,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            categorical_feature=categorical_features,\n",
    "        )\n",
    "        \n",
    "        y_pred_val = clf.predict(x_val)\n",
    "\n",
    "        y_oof[val_idx] = y_pred_val\n",
    "        print(f\"Fold {fold + 1} | AUC Score: {roc_auc_score(y_val, y_pred_val)}\")\n",
    "\n",
    "        score += roc_auc_score(y_val, y_pred_val) / folds\n",
    "        y_preds += clf.predict(x_test) / folds\n",
    "\n",
    "        del x_tr, x_val, y_tr, y_val\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"\\nMean AUC score = {score}\")\n",
    "    print(f\"OOF AUC score = {roc_auc_score(y, y_oof)}\")\n",
    "    \n",
    "    return y_oof, y_preds, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db846129-3893-4c89-acb4-e06fec9f2005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55440000-c414-4248-a0aa-4c69364cbf79",
   "metadata": {},
   "source": [
    "## 모델 성능 확인:\n",
    "\n",
    "학습 데이터: X, y(2007~2018)\n",
    "평가 데이터: test(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8ae780c-7e53-42e1-9dbd-6301a772d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "(1051432, 58) (262858, 58)\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.5 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.5 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] Number of positive: 222028, number of negative: 829404\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1783\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051432, number of used features: 57\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.5 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211167 -> initscore=-1.317904\n",
      "[LightGBM] [Info] Start training from score -1.317904\n",
      "Fold 1 | AUC Score: 0.766894113627278\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_oof_lgb, y_preds_lgb, mdl \u001b[38;5;241m=\u001b[39m \u001b[43mmake_lgb_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 39\u001b[0m, in \u001b[0;36mmake_lgb_prediction\u001b[0;34m(train, y, test, features, categorical_features, model_params, folds)\u001b[0m\n\u001b[1;32m     36\u001b[0m     y_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_test) \u001b[38;5;241m/\u001b[39m folds\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m x_tr, x_val, y_tr, y_val\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mgc\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMean AUC score = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOOF AUC score = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc_score(y,\u001b[38;5;250m \u001b[39my_oof)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "y_oof_lgb, y_preds_lgb, mdl = make_lgb_prediction(X, y, test, features, model_params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a16bb-94d2-4f5a-95cf-5ab099ba303a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
